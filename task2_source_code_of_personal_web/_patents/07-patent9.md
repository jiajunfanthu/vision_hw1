---
title: "Unified framework for model-free reinforcement learning algorithms"
collection: patents
permalink: /patent/2021/05/07-patent9
excerpt: 'The present disclosure relates to a method, a device, a deep reinforcement learning framework, a medium, and a device for determining hyperparameters. The method includes: obtaining a sampling sample corresponding to the sampling value under the sampling value of the target hyperparameter of the target model; The sampled sample generates an interactive sample corresponding to the target hyperparameter, and the interactive sample contains the sampled value and the optimized feature parameter corresponding to the target model; according to the interactive sample, the state value corresponding to the target hyperparameter is updated, The parameter space of the target hyperparameter is discretized into multiple value regions; the target region is determined from the multiple value regions according to the state value corresponding to the updated target hyperparameter; the target value of the target hyperparameter is determined according to the target region . As a result, the value of the hyperparameter of the model can be accurately set, and the phenomenon that the target model cannot converge or the convergence speed is too slow due to the improper hyperparameter setting value due to the limitation of human experience can be avoided.'
date: 2021/05/07
venue: 'State Intellectual Property Office'
citation: 'Fan, J., Xiao, C. Unified framework for model-free reinforcement learning algorithms.CN112766497A[P].2021.05.07.'
---
The present disclosure relates to a method, a device, a deep reinforcement learning framework, a medium, and a device for determining hyperparameters. The method includes: obtaining a sampling sample corresponding to the sampling value under the sampling value of the target hyperparameter of the target model; The sampled sample generates an interactive sample corresponding to the target hyperparameter, and the interactive sample contains the sampled value and the optimized feature parameter corresponding to the target model; according to the interactive sample, the state value corresponding to the target hyperparameter is updated, The parameter space of the target hyperparameter is discretized into multiple value regions; the target region is determined from the multiple value regions according to the state value corresponding to the updated target hyperparameter; the target value of the target hyperparameter is determined according to the target region . As a result, the value of the hyperparameter of the model can be accurately set, and the phenomenon that the target model cannot converge or the convergence speed is too slow due to the improper hyperparameter setting value due to the limitation of human experience can be avoided.

Recommended citation: Fan, J., Xiao, C. Unified framework for model-free reinforcement learning algorithms.CN112766497A[P].2021.05.07.